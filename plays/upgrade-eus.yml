---
- name: "upgrader : Get current version"
  command:
    chdir: "{{ '~' + ansible_user }}/clusterconfigs/auth"
    cmd: oc get clusterversion
  register: current_version

- name: "upgrader : Print current version"
  debug:
    var: current_version.stdout_lines

- name: "upgrader : Get target openshift version from job.components"
  set_fact:
    version: "{{ item['name'] }}"
  with_items: "{{ hostvars.localhost.job_info.job.components }}"
  when: item["type"] == "ocp"

- name: Set variables from localhost facts
  set_fact:
    major: "{{ hostvars.localhost.major }}"
    major_inter: "{{ hostvars.localhost.major_inter }}"
    ocp_major: "{{ hostvars.localhost.ocp_major }}"
    ocp_minor: "{{ hostvars.localhost.ocp_minor }}"

- name: "Set version_inter if not exists"
  set_fact:
    version_inter: "{{ hostvars.localhost.version_inter }}"
  when: version_inter is undefined

- name: "Acknowledge deprecated API removals for 4.9 upgrade"
  community.kubernetes.k8s:
    definition:
      kind: ConfigMap
      metadata:
        name: admin-acks
        namespace: openshift-config
      data:
        ack-4.8-kube-1.22-api-removals-in-4.9: "true"
  when:
    - major_inter is version("4.9", "==")

- name: "Don't upgrade worker nodes"
  community.kubernetes.k8s:
    definition:
      kind: MachineConfigPool
      metadata:
        name: worker
      spec:
        pause: true

- block:
  - name: "upgrader : Fetch release digest"
    uri:
      url: "{{ webserver_url }}/{{ version_inter }}/release.dig"
      return_content: true
    register: release_digest

  - name: "upgrader : Fetch signature for target release"
    get_url:
      url: "{{ webserver_url }}/{{ version_inter }}/signature.yaml"
      dest: ~/clusterconfigs/signature-{{ version_inter }}.yaml
      mode: 0644

  - name: "upgrader : Fetch imagecontentsourcepolicy for target release"
    get_url:
      url: "{{ webserver_url }}/{{ version_inter }}/imagecontentsourcepolicy.yaml"
      dest: ~/clusterconfigs/imagecontentsourcepolicy-{{ version_inter }}.yaml
      mode: 0644

  - name: "upgrader : Apply signatures to cluster"
    command:
      chdir: "{{ '~' + ansible_user }}/clusterconfigs/auth"
      cmd: oc apply -f ../signature-{{ version_inter }}.yaml

  - name: "upgrader : Apply imagecontentsourcepolicy to cluster"
    command:
      chdir: "{{ '~' + ansible_user }}/clusterconfigs/auth"
      cmd: oc apply -f ../imagecontentsourcepolicy-{{ version_inter }}.yaml

  - name: "upgrader : Wait for nodes to become Ready"
    shell:
      chdir: "{{ '~' + ansible_user }}/clusterconfigs/auth"
      cmd: |
        for node in $(oc get nodes -o name); do
          oc wait --timeout=5m --for=condition=Ready ${node} &
        done
        wait -n
    register: wait_for_nodes
    retries: 4
    until: wait_for_nodes.rc == 0

  - name: "upgrader : Patch clusterversion to point to custom upstream graph"
    shell:
      chdir: "{{ '~' + ansible_user }}/clusterconfigs/auth"
      cmd: >
        oc patch clusterversion/version
        --patch '{"spec": {"upstream": "{{ webserver_url }}/graph-{{ major }}" } }'
        --type merge

  - name: "upgrader : Fetch release file for target release"
    get_url:
      url: "{{ webserver_url }}/{{ version_inter }}/release.txt"
      dest: "{{ '~' + ansible_user }}/clusterconfigs/release-{{ version_inter }}.txt"
      mode: 0644

  - name: "Get digest for release"
    shell: >
      grep '^Digest:' {{ '~' + ansible_user }}/clusterconfigs/release-{{ version_inter }}.txt
      | tr -s ' '
      | cut -d ' ' -f 2
    register: release_digest
    changed_when: false
  when:
  - dci_disconnected | default(false) | bool

- name: "upgrader : Patch clusterversion pointing to EUS channel and refresh"
  shell:
    chdir: "{{ '~' + ansible_user }}/clusterconfigs/auth"
    cmd: >
      oc patch clusterversion/version
      --patch '{"spec": {"channel": "eus-{{ major }}"} }'
      --type=merge &&
      oc delete pod
      --namespace=openshift-cluster-version
      --selector=k8s-app=cluster-version-operator &&
      sleep 1 &&
      oc wait pod
      --for=condition=Ready
      --namespace=openshift-cluster-version
      --timeout=5m
      --selector=k8s-app=cluster-version-operator

- name: "upgrader : Execute the intermediate upgrade"
  vars:
    release_version: >-
      {{ dci_disconnected | default |
         ternary(
           '@' + release_digest.stdout,
           ':' + version_inter ) }}
    upgrade_options: >-
      {{ '--to-image=quay.io/openshift-release-dev/ocp-release' +
      release_version + ' --force --allow-explicit-upgrade' }}
  command:
    chdir: "{{ '~' + ansible_user }}/clusterconfigs/auth"
    cmd: oc adm upgrade {{ upgrade_options }}
  register: start_upgrade

- name: "upgrader : Wait for upgrade to start"
  community.kubernetes.k8s_info:
    kind: ClusterVersion
    name: version
  register: cluster_version_info
  vars:
    cluster_version_conditions: '{{ cluster_version_info.resources.0.status.conditions }}'
    condition_progressing: '{{ cluster_version_conditions | selectattr("type", "equalto", "Progressing") | first }}'
  until: ("Working towards " + version_inter) in condition_progressing.message
  retries: 20
  delay: 60

- name: "upgrader : Monitor upgrade until complete"
  shell: |
    set -o pipefail

    FSM=progressing

    function log {
        if [ -n "$VERBOSE" ]
        then
            echo $(date +%Y-%m-%d_%M:%S): $1 > /dev/stderr
        fi
    }

    while true
    do
        OC=$(oc get clusterversion/version -o json)
        FAILING=$(echo ${OC} | jq -r '.status.conditions[] | select(.type == "Failing").message')
        FAILING_STATUS=$(echo ${OC} | jq -r '.status.conditions[] | select(.type == "Failing").status' | grep "True")
        IS_FAILING=$?

        AVAILABLE=$(echo ${OC} | jq -r '.status.conditions[] | select(.type == "Available").message' | grep "Done applying {{ version_inter }}")
        IS_COMPLETE=$?

        if [ "$FSM" == "progressing" ]
        then
            log "Currently progressing"
            if [ "$IS_COMPLETE" == 0 ]
            then
                echo $AVAILABLE
                exit 0
            elif [ "$IS_FAILING" == 0 ]
            then
                log "Changing FSM to failing"
                FSM=failing
                FAILING_TS=$(date +%s)
            fi
        elif [ "$FSM" == "failing" ]
        then
            TS=$(date +%s)
            LAPSE=$(( TS - FAILING_TS ))
            log "Lapse: " ${LAPSE}
            if [ "$IS_FAILING" == 1 ]
            then
                log "Changing FSM to progressing"
                FSM=progressing
                FAILING_TS=0
            elif [ $LAPSE -ge 900 ]
            then
                echo $FAILING
                exit 1
            else
                echo log $FAILING
            fi
        fi

        sleep 15
    done
  args:
    chdir: "{{ '~' + ansible_user }}/clusterconfigs/auth"
  async: 7200
  poll: 15

- name: "test_ upgrader: check if all cluster-operators are running correctly"
  shell:
    chdir: "{{ '~' + ansible_user }}/clusterconfigs/auth"
    cmd: >
      oc get clusteroperator -o json | jq -r '  { "op": [.items[].status.conditions[]] }'
  register: cluster_operators
  failed_when: "cluster_operators.stdout | from_json | json_query('length(op[?(type==\"Degraded\" && status==\"True\")])') > 0"

- block:
  - name: "upgrader : Fetch release digest"
    uri:
      url: "{{ webserver_url }}/{{ version }}/release.dig"
      return_content: true
    register: release_digest

  - name: "upgrader : Fetch signature for target release"
    get_url:
      url: "{{ webserver_url }}/{{ version }}/signature.yaml"
      dest: ~/clusterconfigs/signature-{{ version }}.yaml
      mode: 0644

  - name: "upgrader : Fetch imagecontentsourcepolicy for target release"
    get_url:
      url: "{{ webserver_url }}/{{ version }}/imagecontentsourcepolicy.yaml"
      dest: ~/clusterconfigs/imagecontentsourcepolicy-{{ version }}.yaml
      mode: 0644

  - name: "upgrader : Apply signatures to cluster"
    command:
      chdir: "{{ '~' + ansible_user }}/clusterconfigs/auth"
      cmd: oc apply -f ../signature-{{ version }}.yaml

  - name: "upgrader : Apply imagecontentsourcepolicy to cluster"
    command:
      chdir: "{{ '~' + ansible_user }}/clusterconfigs/auth"
      cmd: oc apply -f ../imagecontentsourcepolicy-{{ version }}.yaml

  - name: "Wait for updated MCP after applying an ICSP"
    include_role:
      name: check-resource
    vars:
      resource_to_check: "MachineConfigPool"
      check_wait_retries: 30
      check_wait_delay: 10
      check_reason: "EUS Upgrade - after applying ICSP"

  - name: "upgrader : Wait for nodes to become Ready"
    shell:
      chdir: "{{ '~' + ansible_user }}/clusterconfigs/auth"
      cmd: |
        for node in $(oc get nodes -o name); do
          oc wait --timeout=5m --for=condition=Ready ${node} &
        done
        wait -n
    register: wait_for_nodes
    retries: 4
    until: wait_for_nodes.rc == 0

  - name: "upgrader : Patch clusterversion to point to custom upstream graph"
    shell:
      chdir: "{{ '~' + ansible_user }}/clusterconfigs/auth"
      cmd: >
        oc patch clusterversion/version
        --patch '{"spec": {"upstream": "{{ webserver_url }}/graph-{{ major }}" } }'
        --type merge

  - name: "upgrader : Fetch release file for target release"
    get_url:
      url: "{{ webserver_url }}/{{ version }}/release.txt"
      dest: "{{ '~' + ansible_user }}/clusterconfigs/release-{{ version }}.txt"
      mode: 0644

  - name: "Get digest for release"
    shell: >
      grep '^Digest:' {{ '~' + ansible_user }}/clusterconfigs/release-{{ version }}.txt
      | tr -s ' '
      | cut -d ' ' -f 2
    register: release_digest
    changed_when: false
  when:
  - dci_disconnected | default(false) | bool

- name: "upgrader : Execute the intermediate upgrade"
  vars:
    release_version: >-
      {{ dci_disconnected | default |
         ternary(
           '@' + release_digest.stdout,
           ':' + version ) }}
    upgrade_options: >-
      {{ '--to-image=quay.io/openshift-release-dev/ocp-release' +
      release_version + ' --force --allow-explicit-upgrade' }}
  command:
    chdir: "{{ '~' + ansible_user }}/clusterconfigs/auth"
    cmd: oc adm upgrade {{ upgrade_options }}
  register: start_upgrade

- name: "upgrader : Wait for upgrade to start"
  community.kubernetes.k8s_info:
    kind: ClusterVersion
    name: version
  register: cluster_version_info
  vars:
    cluster_version_conditions: '{{ cluster_version_info.resources.0.status.conditions }}'
    condition_progressing: '{{ cluster_version_conditions | selectattr("type", "equalto", "Progressing") | first }}'
  until: ("Working towards " + version) in condition_progressing.message
  retries: 20
  delay: 60

- name: "upgrader : Monitor upgrade until complete"
  shell: |
    set -o pipefail

    FSM=progressing

    function log {
        if [ -n "$VERBOSE" ]
        then
            echo $(date +%Y-%m-%d_%M:%S): $1 > /dev/stderr
        fi
    }

    while true
    do
        OC=$(oc get clusterversion/version -o json)
        FAILING=$(echo ${OC} | jq -r '.status.conditions[] | select(.type == "Failing").message')
        FAILING_STATUS=$(echo ${OC} | jq -r '.status.conditions[] | select(.type == "Failing").status' | grep "True")
        IS_FAILING=$?

        AVAILABLE=$(echo ${OC} | jq -r '.status.conditions[] | select(.type == "Available").message' | grep "Done applying {{ version }}")
        IS_COMPLETE=$?

        if [ "$FSM" == "progressing" ]
        then
            log "Currently progressing"
            if [ "$IS_COMPLETE" == 0 ]
            then
                echo $AVAILABLE
                exit 0
            elif [ "$IS_FAILING" == 0 ]
            then
                log "Changing FSM to failing"
                FSM=failing
                FAILING_TS=$(date +%s)
            fi
        elif [ "$FSM" == "failing" ]
        then
            TS=$(date +%s)
            LAPSE=$(( TS - FAILING_TS ))
            log "Lapse: " ${LAPSE}
            if [ "$IS_FAILING" == 1 ]
            then
                log "Changing FSM to progressing"
                FSM=progressing
                FAILING_TS=0
            elif [ $LAPSE -ge 900 ]
            then
                echo $FAILING
                exit 1
            else
                echo log $FAILING
            fi
        fi

        sleep 15
    done
  args:
    chdir: "{{ '~' + ansible_user }}/clusterconfigs/auth"
  async: 9000
  poll: 15

- name: "test_ upgrader: check if all cluster-operators are running correctly"
  shell:
    chdir: "{{ '~' + ansible_user }}/clusterconfigs/auth"
    cmd: >
      oc get clusteroperator -o json | jq -r '  { "op": [.items[].status.conditions[]] }'
  register: cluster_operators
  failed_when: "cluster_operators.stdout | from_json | json_query('length(op[?(type==\"Degraded\" && status==\"True\")])') > 0"

- name: "Reactivate the upgrade of worker nodes"
  community.kubernetes.k8s:
    definition:
      kind: MachineConfigPool
      metadata:
        name: worker
      spec:
        pause: false

- name: "Validate that nodes are Ready and MCPs are up to date"
  include_role:
    name: check-resource
  vars:
    resource_to_check: "MachineConfigPool"
    check_wait_retries: 200
    check_wait_delay: 10
    check_reason: "EUS Upgrade - after having operators running"

- block:
  - name: Set release_url
    set_fact:
      release_url: "{{ (webserver_url|default|length) | ternary(webserver_url|default, 'https://mirror.openshift.com/pub/openshift-v4/clients/ocp') }}"

  - name: Get the ocp client tar gunzip file
    get_url:
      url: "{{ release_url }}/{{ version }}/openshift-client-linux-{{ version }}.tar.gz"
      dest: /tmp/
      mode: '0755'

  - name: "Untar the openshift-client-linux-{{ version }}.tar.gz"
    unarchive:
      src: "/tmp/openshift-client-linux-{{ version }}.tar.gz"
      dest: "{{ dci_cluster_configs_dir }}"
      mode: '0755'
      remote_src: yes

  - name: "Remove the openshift-client-linux-{{ version }}.tar.gz"
    file:
      path: "/tmp/openshift-client-linux-{{ version }}.tar.gz"
      state: absent
  delegate_to: localhost
  when: provision_cache_store is not defined

- name: "Copy new oc client after upgrade is finished"
  vars:
    pcs: "{{ provision_cache_store | default() }}"
    oc_path: >-
      {{ pcs | length |
         ternary(
           pcs + "/" + version + "/oc",
           dci_cluster_configs_dir + "/oc" ) }}
  copy:
    src: "{{ oc_path }}"
    dest: "/usr/local/bin/oc"
    mode: "0755"
  become: true
...
